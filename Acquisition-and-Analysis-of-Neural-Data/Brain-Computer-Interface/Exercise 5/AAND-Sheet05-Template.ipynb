{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General rules:\n",
    " * For all figures that you generate, remember to add meaningful labels to the axes (including units), and provide a legend and colorbar, if applicable.\n",
    " * Do not hard code constants, like number of samples, number of channels, etc in your program. These values should always be determined from the given data. This way, you can easily use the code to analyse other data sets.\n",
    " * Do not use high-level functions from toolboxes like scikit-learn.\n",
    " * Before submitting, check your code by executing: Kernel -> Restart & run all.\n",
    " * Replace *Template* by your *FirstnameLastname* in the filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAND BCI - Exercise Sheet #05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name: Leonard Hollander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import bci_minitoolbox as bci\n",
    "import bci_classifiers as cfy    # contains train_LDA, crossvalidation and loss_weigthed_error\n",
    "import bci_classifiers2 as cfy2  # contains cov_shrink, train_LDAshrink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_spatialFilter(cnt, clab, chan, neighbors='*'):\n",
    "    '''\n",
    "    Usage:\n",
    "        cnt_sf = proc_spatialFilter(cnt, clab, chan, neighbors='*')\n",
    "    Parameters:\n",
    "        cnt:       a 2D array of multi-channel timeseries (size: channels x samples),\n",
    "        clab:      a 1D array of channel names  (size: channels)\n",
    "        chan:      channel of center location\n",
    "        neighbors: labels of channels that are to be subtracted \n",
    "    Returns:\n",
    "        cnt_sf:    timeseries of spatially filtered channel (size: 1 x samples)\n",
    "    Examples:\n",
    "        cnt_c4_bip = proc_spatialFilter(cnt, clab, 'C4', 'CP4')\n",
    "        cnt_c4_lap = proc_spatialFilter(cnt, clab, 'C4', ['C2','C6','FC4','CP4'])\n",
    "        cnt_c4_car = proc_spatialFilter(cnt, clab, 'C4', '*')\n",
    "    '''\n",
    "    cidx= clab.index(chan)\n",
    "    if isinstance(neighbors, list):\n",
    "        nidx = [clab.index(cc) for cc in neighbors]\n",
    "    elif neighbors == '*':\n",
    "        nidx = range(len(clab))   # Common Average Reference (CAR)\n",
    "    else:\n",
    "        nidx = [clab.index(neighbors)]\n",
    "    cnt_sf = cnt[[cidx],:] - np.mean(cnt[nidx,:], axis=0)\n",
    "    return cnt_sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'X is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a84415cad589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'imagVPaw.npz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrk_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrk_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrk_className\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbci\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Leo's Desktop/swc-python/BCCN/Acquisition-and-Analysis-of-Neural-Data/Brain-Computer-Interface/Exercise 5/bci_minitoolbox.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     25\u001b[0m     '''\n\u001b[1;32m     26\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mclab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clab'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not a file in the archive\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'X is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "fname = 'imagVPaw.npz'\n",
    "cnt, fs, clab, mnt, mrk_pos, mrk_class, mrk_className = bci.load_data(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Determining a Frequency Band  (Solution provided!)\n",
    "Calculate the classwise averaged power spectral density at scalp locations C3 and C4 in the data set `imagVPaw`. For each motor imagery condition, you may use the interval 1000-5000 ms.  Determine a frequency band that seems useful to discriminate the two moto imagery conditions.\n",
    "**Note:** To take into account what was said in the lecture about spectra and spatial filtering, use a bipolar filter for C3 and a Laplace filter for C4. To calculate the average spectra over single trials you can use \n",
    "\n",
    "```>>> f, psd = sp.signal.welch(X.flatten('F'), fs=100)```\n",
    "  \n",
    "assuming the single trials of one channel to be the columns of `X` and sampled at 100Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSD(cnt, fs, mrk_pos, mrk_class, ival):\n",
    "    epo, _ = bci.makeepochs(cnt, fs, mrk_pos, ival)\n",
    "    X1 = epo[:, 0, mrk_class==0]\n",
    "    X2 = epo[:, 0, mrk_class==1]\n",
    "    f1, X1psd = sp.signal.welch(X1.flatten('F'), fs=fs)\n",
    "    f2, X2psd = sp.signal.welch(X2.flatten('F'), fs=fs)\n",
    "\n",
    "    plt.semilogy(f1, X1psd)\n",
    "    plt.semilogy(f2, X2psd)\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.ylabel('PSD [$uV^2$/Hz]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = proc_spatialFilter(cnt, clab, 'C3', 'CP3')\n",
    "c4 = proc_spatialFilter(cnt, clab, 'C4', ['C2','C6','FC4','CP4'])\n",
    "clab_flt = ['C3-CP3', 'C4 lap']\n",
    "\n",
    "plt.figure(figsize=[18, 5])\n",
    "plt.subplot(121)\n",
    "plot_PSD(c3, fs, mrk_pos, mrk_class, [1000, 5000])\n",
    "plt.title(clab_flt[0])\n",
    "plt.legend(mrk_className)\n",
    "plt.subplot(122)\n",
    "plot_PSD(c4, fs, mrk_pos, mrk_class, [1000, 5000])\n",
    "plt.title(clab_flt[1])\n",
    "plt.legend(mrk_className)\n",
    "\n",
    "band = np.array([10.5, 13.]) # \".\" is crucial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Visualizing ERD/ERS curves  (Solution provided!)\n",
    "Design a band-pass filter with the frequency band that was selected in exercises \\#1 (use the band `[11. 16.]` if you did not succeed with that, but note that this band may be suboptimal). For the same channels (and spatial filters) as in exercise \\#1, calculate and display the classwise averaged ERD/ERS curves with respect to the determined frequency band for the time interval that encompasses a prestimulus interval of 500 ms and extends to 6000 ms poststimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wn = band / fs * 2\n",
    "b, a = scipy.signal.butter(5, Wn, btype='bandpass')\n",
    "cnt_flt = np.concatenate((c3, c4), axis=0)\n",
    "cnt_flt = sp.signal.lfilter(b, a, cnt_flt)\n",
    "cnt_hull = np.abs(sp.signal.hilbert(cnt_flt, axis=1))\n",
    "erd, erd_t = bci.makeepochs(cnt_hull, fs, mrk_pos, [-500, 6000])\n",
    "# Alternative version without hilbert transform:\n",
    "#erd, erd_t = bci.makeepochs(cnt_flt, fs, mrk_pos, [-500, 6000])\n",
    "#erd = np.abs(erd)\n",
    "erd0 = np.mean(erd[:,:,mrk_class==0], axis=2)\n",
    "erd1 = np.mean(erd[:,:,mrk_class==1], axis=2)\n",
    "\n",
    "plt.figure(figsize=[18, 6])\n",
    "nChans= len(clab_flt)\n",
    "for i in range(nChans):\n",
    "    plt.subplot(1, nChans, i+1)\n",
    "    plt.plot(erd_t, erd0[:, i], label=mrk_className[0])\n",
    "    plt.plot(erd_t, erd1[:, i], label=mrk_className[1])\n",
    "    plt.title(clab_flt[i])\n",
    "    plt.xlabel('time  [ms]')\n",
    "    plt.ylabel('potential  [uV]')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 0: Classification of single-trial ERD/ERS curves  (3 BONUS points)\n",
    "Subsample the band-pass filtered and rectified epochs of the interval 1000 ms to 5000 ms down to 5 Hz by calculating the average of every consequtive window of 200 ms. Perform crossvalidation of those features separately for each single channel and display the result as scalp map. (In this case, do not use a spatial filter.) Furthermore, perform a 3-fold crossvalidation for the joint feature vector (dimensionality is 20 [time points] `x` 51 [channels]).\n",
    "**Note:** Don't be disappointed if the results are not good. On the next sheet you will implement a powerful method for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erd0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Common Spatial Pattern Analysis  (5 points)\n",
    "Apply a band-pass filter to the given (continuous) EEG signals according to the findings in exercises \\#1 on the last sheet (or use the reference solution [10.5 13] Hz)} and perform a CSP analysis for the time interval 750-4000 ms. Plot the spatial patterns corresponding to the 3 largest and the 3 smallest eigenvalues as scalp maps. Apply the six spatial filters to the band-pass filtered EEG signals. The resulting signals are subsequently called CSP-filtered signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CSP(epo, mrk_class):\n",
    "    ''' Usage: W, D = trainCSP(epo, mrk_class) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are not sucessful implementing train_CSP, or if you are unsure, you can use results from the provided file:\n",
    "# data = np.load('imagVPaw_csp.npz')\n",
    "# W = data['W']\n",
    "# d = data['d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:  Visualizing ERD/ERS curves of CSP channels  (1 point)\n",
    "Take the CSP-filtered signals and visualize the classwise averaged ERD/ERS curves in the 6 channels. (If you did not succeed with exercise \\#1, download the file `imagVPaw_csp}` from the web side, which includes the full filter matrix $\\bf W$ and Eigenvalues $\\bf d$).\n",
    "Use the time interval from -500 ms to 6000 ms. Determine from these curves a time interval which shows a good discrimination of between the two motor imagery conditions for subsequent tasks.\n",
    "**Note:** It would be better to use $r^2$-values for this purpose, but we skip that for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Visualization of log power Features  ( 1 point)\n",
    "Take the CSP-filtered signals, extract single trials in the time interval determined in exercise \\#2 (or 750-4000 ms if you did not succeed) and calculate the log variance within each trial. This gives a six dimensional feature vector for each single trial. Select two of those six dimensions for visualization.  Make a scatter plot with the two selected dimensions on the $x$- resp. $y$-axis and use two different colors for the two conditions.\n",
    "*Optionally, you may add the separation line of an LDA.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Validation of the Classification Procedure  (3 points)\n",
    "Estimate the generalization error of the whole classification procedure using all 6 feature dimensions. Use the first half of the data as training set and the second half as validation set. *Remember what was said in the lecture about validating a CSP-based method!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
